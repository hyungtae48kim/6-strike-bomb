"""
6-Strike-Bomb ë³´ì™„ ì‚¬í•­ ì „ì²´ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸.
7ê°€ì§€ ë³´ì™„ ì‚¬í•­ì„ ëª¨ë‘ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import traceback
import numpy as np
import pandas as pd

# ë°ì´í„° ë¡œë“œ
from utils.fetcher import load_data

df = load_data()
if df.empty:
    print("ERROR: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
    sys.exit(1)

print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} íšŒì°¨")
print("=" * 60)

results = {}


def test(name, func):
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í—¬í¼"""
    print(f"\n[í…ŒìŠ¤íŠ¸] {name}")
    print("-" * 40)
    try:
        func()
        results[name] = "PASS"
        print(f"  âœ… {name}: PASS")
    except Exception as e:
        results[name] = f"FAIL: {e}"
        print(f"  âŒ {name}: FAIL")
        traceback.print_exc()


# ============================================================
# 1. LottoAnalyzer í…ŒìŠ¤íŠ¸
# ============================================================
def test_analyzer():
    from utils.analysis import LottoAnalyzer

    analyzer = LottoAnalyzer()

    # ACê°’ í…ŒìŠ¤íŠ¸: [1,2,3,4,5,6] â†’ 15ìŒ, ì°¨ì´ê°’ {1,2,3,4,5} â†’ 5 - 5 = 0... ì•„ë‹ˆë‹¤
    # ì°¨ì´ê°’: 1-2=1, 1-3=2, 1-4=3, 1-5=4, 1-6=5, 2-3=1, 2-4=2, 2-5=3, 2-6=4,
    #         3-4=1, 3-5=2, 3-6=3, 4-5=1, 4-6=2, 5-6=1
    # ê³ ìœ  ì°¨ì´: {1,2,3,4,5} â†’ 5ê°œ â†’ AC = 5-5 = 0
    ac = analyzer.ac_value([1, 2, 3, 4, 5, 6])
    assert ac == 0, f"AC([1,2,3,4,5,6]) = {ac}, expected 0"

    # [1,7,13,19,25,31]: ë“±ì°¨ìˆ˜ì—´(ê°„ê²© 6)
    # ì°¨ì´: 6,12,18,24,30, 6,12,18,24, 6,12,18, 6,12, 6
    # ê³ ìœ : {6,12,18,24,30} â†’ 5ê°œ â†’ AC = 5-5 = 0
    ac2 = analyzer.ac_value([1, 7, 13, 19, 25, 31])
    assert ac2 == 0, f"AC([1,7,13,19,25,31]) = {ac2}, expected 0"

    # [1,5,15,22,33,44]: ë‹¤ì–‘í•œ ê°„ê²©
    ac3 = analyzer.ac_value([1, 5, 15, 22, 33, 44])
    assert ac3 >= 5, f"AC should be high for diverse combo, got {ac3}"

    # í•©ê³„ í…ŒìŠ¤íŠ¸
    assert analyzer.sum_value([1, 2, 3, 4, 5, 6]) == 21
    assert analyzer.sum_range_check([20, 22, 25, 28, 30, 35])  # sum=160, ë²”ìœ„ ë‚´

    # í™€ì§ í…ŒìŠ¤íŠ¸
    odd, even = analyzer.odd_even_ratio([1, 3, 5, 7, 9, 11])
    assert odd == 6 and even == 0

    # ì—°ë²ˆ í…ŒìŠ¤íŠ¸
    assert analyzer.consecutive_count([1, 2, 3, 10, 20, 30]) == 2  # 1-2, 2-3

    # ë²ˆí˜¸ëŒ€ ë¶„í¬ í…ŒìŠ¤íŠ¸
    decades = analyzer.decade_distribution([3, 15, 22, 31, 40, 44])
    assert decades["1-9"] == 1
    assert decades["40-45"] == 2

    # ì¢…í•© ì ìˆ˜ í…ŒìŠ¤íŠ¸
    score = analyzer.comprehensive_score([3, 15, 22, 31, 38, 44])
    assert isinstance(score, float)

    print(f"  ACê°’ í…ŒìŠ¤íŠ¸ í†µê³¼ (0, 0, {ac3})")
    print(f"  ì¢…í•© ì ìˆ˜ ì˜ˆì‹œ: {score:.1f}")


test("1. LottoAnalyzer", test_analyzer)


# ============================================================
# 2. CombinationFilter í…ŒìŠ¤íŠ¸
# ============================================================
def test_combination_filter():
    from utils.analysis import CombinationFilter

    cf = CombinationFilter(df)

    # ì—­ëŒ€ ë‹¹ì²¨ë²ˆí˜¸ëŠ” ëŒ€ë¶€ë¶„ í•„í„°ë¥¼ í†µê³¼í•´ì•¼ í•¨
    pass_count = 0
    total = min(100, len(df))
    for _, row in df.tail(total).iterrows():
        combo = sorted([int(row[f'drwtNo{i}']) for i in range(1, 7)])
        if cf.filter(combo):
            pass_count += 1

    pass_rate = pass_count / total * 100
    assert pass_rate >= 70, f"ì—­ëŒ€ ë‹¹ì²¨ë²ˆí˜¸ í•„í„° í†µê³¼ìœ¨ {pass_rate:.1f}% < 70%"

    # ë¹„ì •ìƒ ì¡°í•©ì€ í•„í„°ì— ê±¸ë ¤ì•¼ í•¨
    assert not cf.filter([1, 2, 3, 4, 5, 6])  # ì—°ë²ˆ ê³¼ë‹¤ + í•©ê³„ ë„ˆë¬´ ë‚®ìŒ
    assert not cf.filter([40, 41, 42, 43, 44, 45])  # í•©ê³„ ë„ˆë¬´ ë†’ìŒ

    # í•„í„°ë§ëœ ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸
    probs = np.ones(45) / 45
    combo = cf.filtered_sampling(probs)
    assert len(combo) == 6
    assert len(set(combo)) == 6
    assert all(1 <= n <= 45 for n in combo)

    print(f"  ì—­ëŒ€ ë‹¹ì²¨ë²ˆí˜¸ í•„í„° í†µê³¼ìœ¨: {pass_rate:.1f}%")
    print(f"  í•„í„°ë§ ìƒ˜í”Œë§ ê²°ê³¼: {combo}")


test("2. CombinationFilter", test_combination_filter)


# ============================================================
# 3. CombinationScorer í…ŒìŠ¤íŠ¸
# ============================================================
def test_combination_scorer():
    from utils.combination_scorer import CombinationScorer

    cs = CombinationScorer(df)

    # ìƒê´€ê´€ê³„ í–‰ë ¬ ì°¨ì› ê²€ì¦
    assert cs.correlation.shape == (45, 45), f"ìƒê´€ê´€ê³„ í–‰ë ¬ í¬ê¸°: {cs.correlation.shape}"

    # ì¡°ê±´ë¶€ í™•ë¥  ì°¨ì› ê²€ì¦
    assert cs.cond_probs.shape == (45, 45), f"ì¡°ê±´ë¶€ í™•ë¥  í¬ê¸°: {cs.cond_probs.shape}"

    # ëŒ€ê°ì„ ì€ 0 (ìê¸° ìì‹  ì œì™¸)
    for i in range(45):
        assert cs.cond_probs[i][i] == 0, f"cond_probs[{i}][{i}] != 0"

    # ì¡°í•© ì ìˆ˜ í…ŒìŠ¤íŠ¸
    probs = np.ones(45) / 45
    score = cs.score_combination([1, 10, 20, 30, 40, 45], probs)
    assert isinstance(score, float) and np.isfinite(score)

    # ì¡°ê±´ë¶€ ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸
    combo = cs.adjusted_sampling(probs)
    assert len(combo) == 6
    assert len(set(combo)) == 6
    assert all(1 <= n <= 45 for n in combo)
    assert combo == sorted(combo)

    print(f"  ìƒê´€ê´€ê³„ í–‰ë ¬: {cs.correlation.shape}")
    print(f"  ì¡°ê±´ë¶€ ìƒ˜í”Œë§: {combo}")
    print(f"  ì¡°í•© ì ìˆ˜: {score:.4f}")


test("3. CombinationScorer", test_combination_scorer)


# ============================================================
# 4. Walk-Forward Validator í…ŒìŠ¤íŠ¸
# ============================================================
def test_validation():
    from utils.validation import WalkForwardValidator
    from models.stats_model import StatsModel

    validator = WalkForwardValidator(
        initial_train_size=800,
        test_size=3,
        step_size=200
    )

    result = validator.validate(StatsModel, df)

    assert result.n_folds > 0, "ê²€ì¦ í´ë“œ ì—†ìŒ"
    assert 0 <= result.avg_hits <= 6, f"í‰ê·  ì ì¤‘ ë²”ìœ„ ì˜¤ë¥˜: {result.avg_hits}"
    assert result.hit_distribution, "ì ì¤‘ ë¶„í¬ ë¹„ì–´ìˆìŒ"

    # ê³¼ì í•© íƒì§€ í…ŒìŠ¤íŠ¸
    overfit = WalkForwardValidator.detect_overfit(result)
    assert "severity" in overfit
    assert "is_overfit" in overfit

    print(f"  í´ë“œ ìˆ˜: {result.n_folds}")
    print(f"  í‰ê·  ì ì¤‘: {result.avg_hits:.3f}")
    print(f"  ê³¼ì í•© ê°­: {result.overfit_gap:.3f}")
    print(f"  ê³¼ì í•© ì§„ë‹¨: {overfit['severity']}")


test("4. Walk-Forward Validation", test_validation)


# ============================================================
# 5. LSTM ìˆ˜ì • í…ŒìŠ¤íŠ¸ (BCEWithLogitsLoss)
# ============================================================
def test_lstm_fix():
    from models.lstm_model import LSTMModel

    model = LSTMModel(epochs=10, seq_length=10)
    model.train(df)

    pred = model.predict()
    assert len(pred) == 6, f"ì˜ˆì¸¡ ê¸¸ì´: {len(pred)}"
    assert len(set(pred)) == 6, "ì¤‘ë³µ ë²ˆí˜¸"
    assert all(1 <= n <= 45 for n in pred), "ë²”ìœ„ ì˜¤ë¥˜"

    probs = model.get_probability_distribution()
    assert probs.shape == (45,), f"í™•ë¥  ë²¡í„° í¬ê¸°: {probs.shape}"
    assert abs(probs.sum() - 1.0) < 0.01, f"í™•ë¥  í•©: {probs.sum()}"
    assert all(p >= 0 for p in probs), "ìŒìˆ˜ í™•ë¥  ì¡´ì¬"

    print(f"  ì˜ˆì¸¡: {pred}")
    print(f"  í™•ë¥  í•©: {probs.sum():.6f}")


test("5. LSTM ìˆ˜ì • (BCEWithLogitsLoss)", test_lstm_fix)


# ============================================================
# 6. Transformer ìˆ˜ì • í…ŒìŠ¤íŠ¸
# ============================================================
def test_transformer_fix():
    from models.transformer_model import TransformerModel

    model = TransformerModel(epochs=10, seq_length=10)
    model.train(df)

    pred = model.predict()
    assert len(pred) == 6
    assert len(set(pred)) == 6
    assert all(1 <= n <= 45 for n in pred)

    probs = model.get_probability_distribution()
    assert probs.shape == (45,)
    assert abs(probs.sum() - 1.0) < 0.01
    assert all(p >= 0 for p in probs)

    print(f"  ì˜ˆì¸¡: {pred}")
    print(f"  í™•ë¥  í•©: {probs.sum():.6f}")


test("6. Transformer ìˆ˜ì • (BCEWithLogitsLoss)", test_transformer_fix)


# ============================================================
# 7. DeepSets ëª¨ë¸ í…ŒìŠ¤íŠ¸
# ============================================================
def test_deepsets():
    from models.deepsets_model import DeepSetsModel

    model = DeepSetsModel(epochs=10, seq_length=10)
    model.train(df)

    pred = model.predict()
    assert len(pred) == 6, f"ì˜ˆì¸¡ ê¸¸ì´: {len(pred)}"
    assert len(set(pred)) == 6, "ì¤‘ë³µ ë²ˆí˜¸"
    assert all(1 <= n <= 45 for n in pred), "ë²”ìœ„ ì˜¤ë¥˜"
    assert pred == sorted(pred), "ì •ë ¬ ì•ˆë¨"

    probs = model.get_probability_distribution()
    assert probs.shape == (45,), f"í™•ë¥  ë²¡í„° í¬ê¸°: {probs.shape}"
    assert abs(probs.sum() - 1.0) < 0.01, f"í™•ë¥  í•©: {probs.sum()}"

    print(f"  ì˜ˆì¸¡: {pred}")
    print(f"  í™•ë¥  í•©: {probs.sum():.6f}")


test("7. DeepSets ëª¨ë¸", test_deepsets)


# ============================================================
# 8. Wheeling System í…ŒìŠ¤íŠ¸
# ============================================================
def test_wheeling():
    from utils.wheeling import WheelingSystem
    from itertools import combinations

    numbers = [3, 7, 12, 18, 25, 31, 37, 42, 44, 45]
    ws = WheelingSystem(numbers, guarantee_match=3)
    wheel = ws.generate_abbreviated_wheel()

    assert len(wheel) > 0, "íœ ì´ ë¹„ì–´ìˆìŒ"

    # ëª¨ë“  3-ë¶€ë¶„ì§‘í•©ì´ ì»¤ë²„ë˜ëŠ”ì§€ ê²€ì¦
    all_3_subsets = list(combinations(numbers, 3))
    covered = set()
    for ticket in wheel:
        ticket_set = set(ticket)
        for j, subset in enumerate(all_3_subsets):
            if set(subset).issubset(ticket_set):
                covered.add(j)

    coverage = len(covered) / len(all_3_subsets) * 100
    assert coverage == 100, f"ì»¤ë²„ë¦¬ì§€ {coverage:.1f}% < 100%"

    # ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸
    report = ws.get_coverage_report(wheel)
    assert "ì´_í‹°ì¼“_ìˆ˜" in report
    assert "ì»¤ë²„ë¦¬ì§€" in report

    full_wheel = ws.generate_full_wheel()
    saving = (1 - len(wheel) / len(full_wheel)) * 100

    print(f"  í›„ë³´ ë²ˆí˜¸: {numbers}")
    print(f"  ì¶•ì•½ íœ  í‹°ì¼“: {len(wheel)}ì¥ (ì™„ì „ íœ  {len(full_wheel)}ì¥ ëŒ€ë¹„ {saving:.1f}% ì ˆê°)")
    print(f"  3-ë§¤ì¹˜ ì»¤ë²„ë¦¬ì§€: {coverage:.1f}%")


test("8. Wheeling System", test_wheeling)


# ============================================================
# 9. MetaLearner í…ŒìŠ¤íŠ¸
# ============================================================
def test_meta_learner():
    from utils.meta_learner import MetaLearner
    from models.stats_model import StatsModel
    from models.bayes_model import BayesModel

    ml = MetaLearner()

    # softmax ê°€ì¤‘ì¹˜ í…ŒìŠ¤íŠ¸
    scores = {"A": 1.0, "B": 0.5, "C": 0.8}
    weights = ml._softmax_weights(scores)
    assert len(weights) == 3
    assert all(w > 0 for w in weights.values())

    # BMA í…ŒìŠ¤íŠ¸
    probs_a = np.random.dirichlet(np.ones(45))
    probs_b = np.random.dirichlet(np.ones(45))
    model_probs = {"A": probs_a, "B": probs_b}
    model_scores = {"A": 1.5, "B": 0.8}

    bma = ml.bayesian_model_averaging(model_probs, model_scores)
    assert bma.shape == (45,), f"BMA í¬ê¸°: {bma.shape}"
    assert abs(bma.sum() - 1.0) < 0.01, f"BMA í•©: {bma.sum()}"

    # ìºì‹œ ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸
    test_weights = {"Stats": 1.2, "Bayes": 0.8}
    ml.save_cached_weights(test_weights, "data/test_weights_cache.json")
    loaded = ml.load_cached_weights("data/test_weights_cache.json")
    assert loaded == test_weights

    # ì •ë¦¬
    import os
    os.remove("data/test_weights_cache.json")

    print(f"  softmax ê°€ì¤‘ì¹˜: {weights}")
    print(f"  BMA í•©: {bma.sum():.6f}")


test("9. MetaLearner", test_meta_learner)


# ============================================================
# 10. Stacking Ensemble í…ŒìŠ¤íŠ¸
# ============================================================
def test_stacking():
    from models.stacking_ensemble_model import StackingEnsembleModel

    model = StackingEnsembleModel(meta_model_type='ridge')
    model.train(df)

    pred = model.predict()
    assert len(pred) == 6, f"ì˜ˆì¸¡ ê¸¸ì´: {len(pred)}"
    assert len(set(pred)) == 6, "ì¤‘ë³µ ë²ˆí˜¸"
    assert all(1 <= n <= 45 for n in pred), "ë²”ìœ„ ì˜¤ë¥˜"

    probs = model.get_probability_distribution()
    assert probs.shape == (45,), f"í™•ë¥  ë²¡í„° í¬ê¸°: {probs.shape}"
    assert abs(probs.sum() - 1.0) < 0.01, f"í™•ë¥  í•©: {probs.sum()}"

    # predict_multiple í…ŒìŠ¤íŠ¸
    multi = model.predict_multiple(3)
    assert len(multi) == 3
    for m in multi:
        assert len(m) == 6

    # get_top_numbers í…ŒìŠ¤íŠ¸
    top = model.get_top_numbers(10)
    assert len(top) == 10

    print(f"  ì˜ˆì¸¡: {pred}")
    print(f"  ë‹¤ì¤‘ ì˜ˆì¸¡: {len(multi)}ì„¸íŠ¸")


test("10. Stacking Ensemble", test_stacking)


# ============================================================
# 11. Enum ì—…ë°ì´íŠ¸ ê²€ì¦
# ============================================================
def test_enums():
    from models.enums import AlgorithmType

    assert hasattr(AlgorithmType, 'DEEPSETS'), "DEEPSETS enum ì—†ìŒ"
    assert hasattr(AlgorithmType, 'STACKING'), "STACKING enum ì—†ìŒ"
    assert AlgorithmType.DEEPSETS.value == "DeepSets"
    assert AlgorithmType.STACKING.value == "Stacking Ensemble"

    # ì „ì²´ enum ìˆ˜ ê²€ì¦ (ê¸°ì¡´ 12 + ì‹ ê·œ 2 = 14)
    all_types = list(AlgorithmType)
    assert len(all_types) == 14, f"AlgorithmType ìˆ˜: {len(all_types)}, expected 14"

    print(f"  ì´ AlgorithmType: {len(all_types)}")
    print(f"  DEEPSETS: {AlgorithmType.DEEPSETS.value}")
    print(f"  STACKING: {AlgorithmType.STACKING.value}")


test("11. Enum ì—…ë°ì´íŠ¸", test_enums)


# ============================================================
# ê²°ê³¼ ìš”ì•½
# ============================================================
print("\n" + "=" * 60)
print("ê²€ì¦ ê²°ê³¼ ìš”ì•½")
print("=" * 60)

pass_count = sum(1 for v in results.values() if v == "PASS")
total = len(results)

for name, result in results.items():
    icon = "âœ…" if result == "PASS" else "âŒ"
    print(f"  {icon} {name}: {result}")

print(f"\nì´ {total}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {pass_count}ê°œ í†µê³¼ ({pass_count/total*100:.0f}%)")

if pass_count == total:
    print("\nğŸ‰ ëª¨ë“  ë³´ì™„ ì‚¬í•­ì´ ì •ìƒì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!")
else:
    print(f"\nâš ï¸ {total - pass_count}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìœ„ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)
